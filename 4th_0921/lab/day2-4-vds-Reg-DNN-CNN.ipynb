{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./input/daejeon_vds16.csv')\n",
    "df.head()\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "df['ToVol'][:288].plot(rot=45,figsize=(8,5))\n",
    "df['Speed'][:288].plot(rot=45,figsize=(8,5))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = df[['ToVol', 'Occ.Rate']]\n",
    "y = df[['Speed']]\n",
    "y.head()\n",
    "\n",
    "X2 = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X2.head()\n",
    "inv_X = scaler.inverse_transform(X2)\n",
    "print(inv_X[:5])\n",
    "X.shape, y.shape\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                            test_size=0.20, shuffle=False)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape,  y_test.shape)\n",
    "Acc = []\n",
    "\n",
    "### A. 선형회귀(Linear Regression)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "#To retrieve the intercept and For retrieving the slope:\n",
    "print(regressor.intercept_, regressor.coef_)\n",
    "pred_df = pd.DataFrame({'Actual': y_test.values.flatten(), \n",
    "                        'Predicted': y_pred.flatten()})\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Accuracy score: {0}\".format(r2_score(y_test, y_pred)))\n",
    "Acc.append(r2_score(y_test, y_pred))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.ylabel('Speed', fontsize=16)\n",
    "plt.plot(pred_df)\n",
    "plt.legend(['Actual Value', 'Predictions'])\n",
    "plt.show()\n",
    "\n",
    "### B. 인공신경망_딥러닝 (DNN)\n",
    "def reg_dnn(inp_dim):   \n",
    "    model = Sequential()\n",
    "    model.add(Dense(40, input_dim=inp_dim, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(40, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')    \n",
    "    return model\n",
    "\n",
    "model = reg_dnn(inp_dim=X_train.shape[1])            \n",
    "history = model.fit(X_train, y_train, epochs=30, validation_split=0.2)\n",
    "\n",
    "# 훈련 과정 시각화 (손실)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "pred_df = pd.DataFrame({'Actual': y_test.values.flatten(), \n",
    "                        'Predicted': y_pred.flatten()})\n",
    "pred_df.head()\n",
    "\n",
    "# Measure the Accuracy Score\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Acc score : {0}\".format(r2_score(y_test, y_pred)))\n",
    "Acc.append(r2_score(y_test, y_pred))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.ylabel('Speed', fontsize=16)\n",
    "plt.plot(pred_df)\n",
    "plt.legend(['Actual Value', 'Predictions'])\n",
    "plt.show()\n",
    "\n",
    "### C. 1D CNN 회귀\n",
    "X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "print(X_train.shape, X_test.shape)\n",
    "from tensorflow.keras import Sequential,utils\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPool1D, Dropout\n",
    "def reg_cnn():    \n",
    "    model = Sequential()    \n",
    "    model.add(Conv1D(64, kernel_size=(3,), padding='same', activation='relu', \n",
    "                     input_shape = (X_train.shape[1],1)))\n",
    "    model.add(Conv1D(64, kernel_size=(3,), padding='same', activation='relu'))\n",
    "    model.add(Conv1D(64, kernel_size=(5,), padding='same', activation='relu'))    \n",
    "    model.add(Flatten())    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(units = 1))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')    \n",
    "    return model\n",
    "\n",
    "# Model Training\n",
    "model = reg_cnn()\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=30, validation_split=0.2)\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "pred_df = pd.DataFrame({'Actual': y_test.values.flatten(), \n",
    "                        'Predicted': y_pred.flatten()})\n",
    "pred_df.head()\n",
    "\n",
    "# Measure the Accuracy Score\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Acc score: {0}\".format(r2_score(y_test, y_pred)))\n",
    "Acc.append(r2_score(y_test, y_pred))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.ylabel('Speed', fontsize=16)\n",
    "plt.plot(pred_df)\n",
    "plt.legend(['Actual Value', 'Predictions'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(3), Acc, color='green', \n",
    "         linestyle='dashed', linewidth = 3, \n",
    "         marker='o', markerfacecolor='blue', markersize=12) \n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Models')\n",
    "plt.title(\"Accuracies\")\n",
    "plt.xticks(range(3), ['Linear Regression', 'ANN', 'CNN'])\n",
    "plt.show()\n",
    "\n",
    "# PART II.  기억(메모리) 길이를 고려하자. \n",
    "df.head()\n",
    "spd=df.reset_index()['Speed']\n",
    "spd.head()\n",
    "len(spd)\n",
    "plt.plot(spd)\n",
    "windows = 60\n",
    "X, y = [], []\n",
    "for i in range(len(spd)-windows-1):\n",
    "    X.append(spd[i:(i+windows)])\n",
    "    y.append(spd[(i+windows)])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X.shape\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X.shape\n",
    "X[:3]\n",
    "y[:3]\n",
    "\n",
    "\n",
    "# D. RNN으로 예측하자 : Many-to-One 문제로 접근\n",
    "# windows={12, 24, 36, 48, 288}로 증가시키면서 RNN과 LSTM의 성능을 비교해보자\n",
    "\n",
    "X_train_ = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_test_ = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "print(X_train_.shape, X_test_.shape) \n",
    "\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras import metrics\n",
    "def reg_lstm():\n",
    "    model = Sequential()    \n",
    "    model.add(LSTM(60, return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "    model.add(LSTM(60, return_sequences=True))\n",
    "    model.add(LSTM(60 ))\n",
    "    model.add(Dense(1))    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam',\n",
    "                  metrics =[metrics.mae])    \n",
    "    return model\n",
    "\n",
    "# (GPU 경고) LSTM의 기본은 tanh 활성함수를 사용한다. \n",
    "# 만일 LSTM 층에 activation='relu'를 사용하면 \n",
    "# GPU를 이용한 가속 계산이 안된다는 경고문이 생긴다. \n",
    "\n",
    "# Model Training\n",
    "model = reg_lstm()\n",
    "model.summary()\n",
    "history = model.fit(X_train_, y_train, epochs=30, batch_size=16, validation_split=0.2)\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_)\n",
    "y_pred\n",
    "model.evaluate(X_test_, y_test)\n",
    "#inv_y= scaler3.inverse_transform(y)\n",
    "pred_df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
    "pred_df.head()\n",
    "# Measure the Accuracy Score\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Accuracy score of the predictions: {0}\".format(r2_score(y_test, y_pred)))\n",
    "Acc.append(r2_score(y_test, y_pred))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.ylabel('Speed', fontsize=16)\n",
    "plt.plot(pred_df)\n",
    "plt.legend(['Actual Value', 'Predictions'])\n",
    "plt.show()\n",
    "# 7 훈련 과정 시각화 (손실)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Visualising the results\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(y_test, color = 'red', label = 'Real VDS Data')\n",
    "plt.plot(y_pred, color = 'blue', label = 'Predicted VDS Data')\n",
    "plt.title('Traffic Speed Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('VDS (Speed)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### E. ANN 모델 회귀\n",
    "model = reg_dnn(inp_dim=X_train_.shape[1])\n",
    "history = model.fit(X_train_, y_train, epochs=30, validation_split=0.2)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Measure the Accuracy Score\n",
    "from sklearn.metrics import r2_score \n",
    "print(\"Accuracy score of the predictions: {0}\".format(r2_score(y_test, y_pred)))\n",
    "Acc.append(r2_score(y_test, y_pred))\n",
    "\n",
    "pred_df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
    "pred_df.head()\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.ylabel('Speed', fontsize=16)\n",
    "plt.plot(pred_df)\n",
    "plt.legend(['Actual Value', 'Predictions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN\n",
    "model = reg_cnn()\n",
    "model.fit(X_train_, y_train, epochs=30, validation_split=0.2)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_)\n",
    "pred_df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
    "pred_df.head()\n",
    "\n",
    "# Measure the Accuracy Score\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Accuracy score of the predictions: {0}\".format(r2_score(y_test, y_pred)))\n",
    "Acc.append(r2_score(y_test, y_pred))\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.ylabel('Speed', fontsize=16)\n",
    "plt.plot(pred_df)\n",
    "plt.legend(['Actual Value', 'Predictions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Transformer 모델을 적용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):    \n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, \n",
    "                                  dropout=dropout)(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs   \n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation = \"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, \n",
    "                mlp_units, dropout=0, mlp_dropout=0):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):  # This is what stacks our transformer blocks\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"elu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "        \n",
    "    outputs = layers.Dense(1, activation=\"linear\")(x) #this is a pass-through\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "def lr_scheduler(epoch, lr, warmup_epochs=30, decay_epochs=100, \n",
    "                 initial_lr=1e-6, base_lr=1e-3, min_lr=5e-5):\n",
    "    if epoch <= warmup_epochs:\n",
    "        pct = epoch / warmup_epochs\n",
    "        return ((base_lr - initial_lr) * pct) + initial_lr\n",
    "\n",
    "    if epoch > warmup_epochs and epoch < warmup_epochs+decay_epochs:\n",
    "        pct = 1 - ((epoch - warmup_epochs) / decay_epochs)\n",
    "        return ((base_lr - min_lr) * pct) + min_lr\n",
    "\n",
    "    return min_lr\n",
    "\n",
    "callbacks = [ tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "            tf.keras.callbacks.LearningRateScheduler(lr_scheduler)      ]\n",
    "\n",
    "input_shape = X_train_.shape[1:]\n",
    "print(input_shape)\n",
    "model = build_model(input_shape, head_size=46,  num_heads=60,  ff_dim=55,  \n",
    "                    num_transformer_blocks=5, mlp_units=[256], mlp_dropout=0.4, dropout=0.14, )\n",
    "model.compile( loss=\"mean_squared_error\",\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=[\"mean_squared_error\"])\n",
    "model.summary()\n",
    "history = model.fit( X_train_, y_train, validation_split=0.2, epochs=30, batch_size=20, callbacks=callbacks)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test_)\n",
    "pred_df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})\n",
    "pred_df.head()\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Accuracy score of the predictions: {0}\".format(r2_score(y_test, y_pred)))\n",
    "Acc.append(r2_score(y_test, y_pred))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.ylabel('Speed', fontsize=16)\n",
    "plt.plot(pred_df)\n",
    "plt.legend(['Actual Value', 'Predictions'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(4), Acc, color='green', linestyle='dashed', linewidth = 3, \n",
    "         marker='o', markerfacecolor='blue', markersize=12) \n",
    "plt.ylabel('Acc')\n",
    "plt.xlabel('Models')\n",
    "plt.title(\"Accuracies\")\n",
    "plt.xticks(range(4), ['LSTM', 'ANN', 'CNN','Transformer'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝의 러닝커브를 위한 함수를 정의하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (#) Deep Neural Network\n",
    "- MLP와 ReLu를 활용한 신경망을 사용하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kY2smZwEM0-M"
   },
   "source": [
    "# 5. 머신러닝 모델을 만들자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) 연습문제 해보기 : 속도\n",
    "- VDS 데이터의 라벨을 속도(Speed)에 대하여 자신의 라벨을 정의하시오\n",
    "- 예 (20, 50) 등 \n",
    "- 훈련(Train)과 시험(Test)의 정확도 혹은 손실(Loss)를 제출하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) 연습문제 해보기 : 교통량\n",
    "### 교통량(ToVol) 혹은 SmVol로 라벨을 정하는 방법을 적용하세요\n",
    "- 예 (100, 300) 등 \n",
    "- 훈련(Train)과 시험(Test)의 정확도 혹은 손실(Loss)를 제출하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) 연습문제 해보기\n",
    "- VDS 데이터의 라벨을 점유률(Occ.Rate)에 대하여 자신의 라벨을 정의하시오\n",
    "- 예 (8, 16) 등 \n",
    "- 훈련(Train)과 시험(Test)의 정확도 혹은 손실(Loss)를 제출하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) 연습문제 해보기\n",
    "- 머신러닝 방법과 DNN 방법을 비교하여 자장 휼룡한 신경망 방법과 하이퍼파라미터를 설정하세요."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hAi2SkaJM0-M"
   ],
   "name": "lab2-05-vds_ML_kNN.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "duration": 31.125685,
   "end_time": "2020-11-04T17:04:50.944017",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-04T17:04:19.818332",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
